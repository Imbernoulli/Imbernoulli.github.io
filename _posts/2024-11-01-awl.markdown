---
layout: post
title:  "Adapting While Learning: Grounding LLMs for Scientific Problems with Tool Usage Adaptation"
date:   2024-11-01 00:00:00 +00:00
image: /images/awl.png
categories: research
authors: "<b>Bohan Lyu*</b>, Yadi Cao*, Duncan Watson-Parris, Leon Bergen, Taylor Berg-Kirkpatrick, Rose Yu"
venue: "<b>ICML 2025</b>, AAAI 2024 FSS (Oral)"
arxiv: https://arxiv.org/abs/2411.00412
code: https://github.com/Rose-STL-Lab/Adapting-While-Learning
website: https://icml.cc/virtual/2025/poster/44034
selected: true
slides: /pdfs/AWL-FSS.pdf
youtube: https://youtu.be/EPhse_oOdEc?si=5L8PytRUhWp94vXQ
highlight: true
bibtex: |
    @inproceedings{lyuadapting,
        title={Adapting While Learning: Grounding LLMs for Scientific Problems with Tool Usage Adaptation},
        author={Lyu, Bohan and Cao, Yadi and Watson-Parris, Duncan and Bergen, Leon and Berg-Kirkpatrick, Taylor and Yu, Rose},
        booktitle={Forty-second International Conference on Machine Learning}
    }
---
This work proposes a fine-tuning method where LLMs internalize tool-generated solutions (World Knowledge Distillation) and learn to switch between direct answers and tool use for complex problems (Tool Usage Adaptation). It outperforms GPT-4 and Claude-3.5 across six scientific benchmarks.