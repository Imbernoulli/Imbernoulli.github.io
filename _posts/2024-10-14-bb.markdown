---
layout: post
title:  "MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks"
date:   2024-10-14 00:00:00 +00:00
image: /images/bb.png
categories: research
author: "Jiacheng Chen*,  Tianhao Liang*,  Sherman Siu*,  Zhengqing Wang,  Kai Wang, Yubo Wang,  Yuansheng Ni,  Wang Zhu,  Ziyan Jiang,  Bohan Lyu,  Dongfu Jiang, Xuan He,  Yuan Liu,  Hexiang Hu,  Xiang Yue,  Wenhu Chen"
authors: "Jiacheng Chen*,  Tianhao Liang*,  Sherman Siu*,  Zhengqing Wang,  Kai Wang, Yubo Wang,  Yuansheng Ni,  Wang Zhu,  Ziyan Jiang,  Bohan Lyu,  Dongfu Jiang, Xuan He,  Yuan Liu,  Hexiang Hu,  Xiang Yue,  Wenhu Chen"
venue: "Under Peer Review"
arxiv: https://arxiv.org/pdf/2410.10563
code: 
website: https://tiger-ai-lab.github.io/MEGA-Bench/
selected: false
---
MEGA-Bench contains 505 multimodal tasks with diverse data sources, input/output formats, and skill requirements. The benchmark is equiped with a suite of 45 evaluation metrics to handle various output formats beyond multiple-choice questions.